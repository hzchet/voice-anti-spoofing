name: RawNet2_1layer_gru
n_gpu: 1

arch:
  type: RawNet2
  args:
    sinc_kwargs:
      in_channels: 1
      out_channels: 20
      kernel_size: 1024
      min_low_hz: 0
      min_band_hz: 0
      is_fixed: True
      maxpool_kernel_size: 3
      use_abs: False
    
    channels: [20, 20, 20, 128, 128, 128, 128]
    kernel_sizes: [3, 3, 3, 3, 3, 3]
    maxpool_kernel_sizes: [3, 3, 3, 3, 3, 3]
    
    gru_kwargs:
      input_size: 128
      hidden_size: 1024
      num_layers: 1
      batch_first: True
    pre_gru_activations: False
    
    fc_n_features: 1024

data:
  train:
    batch_size: 32
    num_workers: 4
    pin_memory: True
    datasets:
      - type: AVSDataset
        args:
          split: train
          frontend: s1
  
  dev:
    batch_size: 32
    num_workers: 4
    pin_memory: True
    datasets:
      - type: AVSDataset
        args:
          split: dev
          frontend: s1

  eval:
    batch_size: 32
    num_workers: 4
    pin_memory: True
    datasets:
      - type: AVSDataset
        args:
          split: eval
          frontend: s1

  test:
    batch_size: 5
    datasets:
      - type: InferenceDataset
        args:
          path_to_audios: test_audios
          frontend: s1

loss:
  type: CrossEntropyLoss
  args:
    weight: [9.0, 1.0]

train_metrics:
  - type: ScoresExtractor
    args:
      name: "eer"

valid_metrics:
  - type: ScoresExtractor
    args:
        name: "eer"

optimizer:
  type: Adam
  args:
    betas: [0.9, 0.999]
    lr: 0.0001
    weight_decay: 0.0001

lr_scheduler:
  type: ExponentialLR
  args:
    gamma: 1.0

trainer:
  type: Trainer
  save_dir: saved
  epochs: 100
  save_period: 5
  verbosity: 2
  monitor: "min eval_eer"
  early_stop: 100
  visualize: wandb
  wandb_project: voice-anti-spoofing
  wandb_run_name: RawNet2_1layer_gru
  grad_norm_clip: 10
